{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(''), 'core'))\n",
    "from zeropi import ZeroPi\n",
    "import general \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ZeroPi\n",
    "\n",
    "#paramaters to pptimise over\n",
    "EJ = torch.tensor(10.00, requires_grad=True, dtype=torch.double)\n",
    "EL = torch.tensor(0.04, requires_grad=True, dtype=torch.double)\n",
    "ECJ = torch.tensor(20, requires_grad=True, dtype=torch.double)\n",
    "EC = torch.tensor(0.04, requires_grad=True, dtype=torch.double)\n",
    "dEJ = torch.tensor(0.0, requires_grad=True, dtype=torch.double)\n",
    "dCJ = torch.tensor(0.0, requires_grad=True, dtype=torch.double)\n",
    "ECS= torch.tensor(0.1, requires_grad=True, dtype=torch.double)\n",
    "\n",
    "#fixed params of system\n",
    "flux = 0.5\n",
    "ng = 0.1\n",
    "\n",
    "#fixed params of computation\n",
    "ncut = 30\n",
    "hamiltonian_creation_solution = \"manual_discretization_davidson\"\n",
    "discretization_dim = 100\n",
    "\n",
    "\n",
    "zeropi = ZeroPi(EJ=EJ, \n",
    "                 EL=EL , \n",
    "                 ECJ=ECJ, \n",
    "                 EC=EC, \n",
    "                 dEJ=dEJ,\n",
    "                 ECS = ECS, \n",
    "                 dCJ=dCJ, \n",
    "                 flux = flux,\n",
    "                 ng=ng, \n",
    "                 ncut = ncut,\n",
    "                 discretization_dim =discretization_dim,\n",
    "                 hamiltonian_creation_solution=hamiltonian_creation_solution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 180UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 201UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 170UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 211UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 190"
     ]
    }
   ],
   "source": [
    "H = zeropi.manual_discretization_H()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 180UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 201UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 170UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 211UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/core/zeropi.py: 190"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([142.5768, 142.5780], dtype=torch.float64,\n",
       "       grad_fn=<symeig_torchfcnBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, eigvecs = zeropi.esys()\n",
    "eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:56.)\n",
      " /Users/judd/Documents/AD_superconducting_qubit/ADOSC/venv/lib/python3.8/site-packages/torch_sparse/matmul.py: 97"
     ]
    }
   ],
   "source": [
    "t = general.t2_rate(qubit = zeropi, eigvecs=eigvecs, eigvals =eigvals, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0278e-25, dtype=torch.float64)\n",
      "tensor(4.6853e-18, dtype=torch.float64)\n",
      "tensor(2.9898e-24, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(EJ.grad)\n",
    "print(EL.grad)\n",
    "print(dEJ.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
